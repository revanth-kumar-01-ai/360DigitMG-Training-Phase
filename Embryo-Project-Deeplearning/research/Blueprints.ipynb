{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230963ae",
   "metadata": {},
   "source": [
    "# Start the Project ü§©\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e750e31",
   "metadata": {},
   "source": [
    "## Step One \n",
    "### Exploratory Data Analysis\n",
    "**Before Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa8d72",
   "metadata": {},
   "source": [
    "-  Image Count & Class Distribution\n",
    "\n",
    "-  Random Image Visualization\n",
    "\n",
    "-  Image Shape / Size / Channels Check\n",
    "\n",
    "- File Format Check (.jpg / .png / etc.)\n",
    "\n",
    "- Missing / Corrupt / Blank Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64284be7",
   "metadata": {},
   "source": [
    "## Step Two\n",
    "###  Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca8a75",
   "metadata": {},
   "source": [
    "- Image Collection  ‚úÖ\n",
    "\n",
    " Collect all image folders, combine them into one main folder, and assign clear, correct labels for each. Make sure everything is well organized! ‚úÖüóÇÔ∏èüß†\n",
    "\n",
    "  - Example labels like this\n",
    "   \n",
    "    8-cell Grade A, 8-cell Grade B, 8-cell Grade C, Morula Grade A, Morula Grade B, Morula Grade C, Blastocyst Grade A, Blastocyst Grade B, Blastocyst Grade C, Error Images\n",
    "\n",
    "- Make sure all the images are in standard format like .jpg.\n",
    "\n",
    "- Resize\n",
    "\n",
    "- Convert RGB \n",
    "\n",
    "- Data Augmentation (Each folder have 1000 images)\n",
    "\n",
    "- convert to array \n",
    "\n",
    "- Check Duplicate values \n",
    "\n",
    "- Split Data (train, test)\n",
    "\n",
    "- Save the train and test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29de891c",
   "metadata": {},
   "source": [
    "## Step Three\n",
    "###  After Data preprocessing \n",
    "\n",
    "Basic check \n",
    "- shape \n",
    "- Duplicate \n",
    "- Missing values\n",
    "- Range 0 to 1 \n",
    "- RGB\n",
    "- Output count balanced or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ee067d",
   "metadata": {},
   "source": [
    "# Step Four\n",
    "\n",
    "### Model Building \n",
    "\n",
    "##### update to the MLflow \n",
    "\n",
    "- 1. ConvNext\n",
    "- 2. DenseNet201\n",
    "- 3. Efficient_Net_B7\n",
    "- 4. Res_Net_152\n",
    "- 5. Swin_Transformer\n",
    "- 6. Efficient VIT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088c3ee",
   "metadata": {},
   "source": [
    "# Step Five\n",
    "\n",
    "**Check Which Model Gives Highest Accuracy**\n",
    "\n",
    "### In my case, **Efficient VIT** gives the highest accuracy:  \n",
    "##### **Train Accuracy** ‚Äì 99%  \n",
    "##### **Test Accuracy** ‚Äì 95%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868832a",
   "metadata": {},
   "source": [
    "# Step Six\n",
    "\n",
    "### **Model Evaluation Step**\n",
    "\n",
    "#### - ‚úÖ Precision  \n",
    "#### - ‚úÖ Recall  \n",
    "#### - ‚úÖ Cross Validation  \n",
    "#### - ‚úÖ Check with new images ‚Äì does the model give correct results or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4095d",
   "metadata": {},
   "source": [
    "# Model building \n",
    "\n",
    "\n",
    "# model training phase \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6423cea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a:\\\\Artificial intelligence\\\\Intership works\\\\Embryo Project\\\\Embryo-Project-DeepLearning'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff0e7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69f75e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a:\\\\Artificial intelligence\\\\Intership works\\\\Embryo Project\\\\Embryo-Project-DeepLearning'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba64a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update entity \n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    root_dir: Path\n",
    "    trained_model: Path\n",
    "    onnx_model_path32: Path\n",
    "    onnx_model_path16: Path\n",
    "    test_data: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f49f8559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update config manager in `src/config`  \n",
    "from EmbryoQualityCheck.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from EmbryoQualityCheck.utils.common import read_yaml, create_directories \n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH, params_filepath = PARAMS_FILE_PATH):\n",
    "        \"\"\"\n",
    "            read the config and params \n",
    "            and create directories\n",
    "        \"\"\"\n",
    "        # config\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        # params\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        # create dir (main)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \"\"\"\n",
    "        Model Evaluation \n",
    "    \"\"\"\n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        # training \n",
    "        onnx_model = self.config.onnx_model\n",
    "\n",
    "        create_directories([onnx_model.root_dir])\n",
    "\n",
    "        eval_config = EvaluationConfig(\n",
    "            root_dir=Path(onnx_model.root_dir),\n",
    "            trained_model= Path(onnx_model.trained_model),\n",
    "            onnx_model_path32=Path(onnx_model.onnx_model_path32),\n",
    "            onnx_model_path16=Path(onnx_model.onnx_model_path16),\n",
    "            test_data=Path(onnx_model.test_data),\n",
    "        )   \n",
    "        \n",
    "        return eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Update the components \n",
    "\n",
    "# üß† Core ML Libraries\n",
    "import torch\n",
    "import timm\n",
    "import onnx\n",
    "from onnxconverter_common import float16\n",
    "import onnxruntime as ort\n",
    "\n",
    "# üñºÔ∏è Vision & Transforms\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# üìä Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# üîÅ Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# üåê System & OS\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ‚öôÔ∏è Custom Modules\n",
    "from EmbryoQualityCheck import logger\n",
    "\n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def convert_to_onnxModel(self):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # üß† Load the model\n",
    "        model = timm.create_model('efficientvit_b2.r288_in1k', pretrained=False)\n",
    "        model.to(device)\n",
    "        \n",
    "        model.load_state_dict(torch.load(self.config.trained_model))\n",
    "        model.eval()\n",
    "\n",
    "        # üì¶ Dummy input\n",
    "        dummy_input = torch.randn(1, 3, 288, 288).to(device)\n",
    "\n",
    "        # üü† Export to ONNX (FP32)\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            self.config.onnx_model_path32,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            opset_version=11,\n",
    "            export_params=True,\n",
    "            do_constant_folding=True\n",
    "        )\n",
    "\n",
    "        # ‚öíÔ∏è Convert to FP16\n",
    "        model_fp32 = onnx.load(self.config.onnx_model_path32)\n",
    "        model_fp16 = float16.convert_float_to_float16(model_fp32)\n",
    "        onnx.save(model_fp16, self.config.onnx_model_path16)\n",
    "\n",
    "        logger.info(\"ONNX FP16 model saved as efficientvit_embryo_fp16.onnx\")\n",
    "    \n",
    "    # test data evaluation \n",
    "    def TestEvaluation(self):\n",
    "        predict = []\n",
    "        y_true = []\n",
    "\n",
    "        root_path = self.config.test_data\n",
    "\n",
    "\n",
    "        # Load ONNX model\n",
    "        session = ort.InferenceSession(self.config.onnx_model_path16)\n",
    "\n",
    "        # Define transform\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((288, 288)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        # Class names\n",
    "        class_names = [\n",
    "            '8-cell Grade A', '8-cell Grade B', '8-cell Grade C',\n",
    "            'Blastocyst Grade A', 'Blastocyst Grade B', 'Blastocyst Grade C',\n",
    "            'Error Images', 'Morula Grade A', 'Morula Grade B', 'Morula Grade C'\n",
    "        ]\n",
    "\n",
    "        for folder in tqdm(os.listdir(root_path), desc=\"Processing folders\"):\n",
    "            folder_path = os.path.join(root_path, folder)\n",
    "            \n",
    "            for img_name in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, img_name)\n",
    "\n",
    "                # Load and transform image\n",
    "                img = Image.open(image_path).convert(\"RGB\")\n",
    "                img_tensor = transform(img).unsqueeze(0).numpy().astype(np.float16)\n",
    "\n",
    "                # Run inference\n",
    "                outputs = session.run(None, {\"input\": img_tensor})\n",
    "                probs = outputs[0]\n",
    "                pred_class = np.argmax(probs)\n",
    "\n",
    "                # Store prediction and ground truth\n",
    "                predict.append(class_names[pred_class])\n",
    "                y_true.append(folder)  # True label from folder name\n",
    "\n",
    "        logger.info(f'Accuracy {accuracy_score(y_true, predict)}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e509dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-25 19:55:45,000: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-04-25 19:55:45,004: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-04-25 19:55:45,005: INFO: common: created directory at: artifacts]\n",
      "[2025-04-25 19:55:45,007: INFO: common: created directory at: artifacts/onnx_model]\n",
      "ji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folders: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:32<00:00,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-25 19:57:17,388: INFO: 872567979: Accuracy 0.9645464025026069]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Update the pipeline \n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    evaluation_config = config.get_evaluation_config()\n",
    "    evaluation = Evaluation(evaluation_config)\n",
    "    evaluation.convert_to_onnxModel()\n",
    "    evaluation.TestEvaluation()\n",
    "except Exception as e:\n",
    "    raise e \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d45fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
