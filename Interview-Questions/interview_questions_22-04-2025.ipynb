{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9397603",
   "metadata": {},
   "source": [
    "# Interview Question \n",
    "\n",
    "**22-04-2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7565f336",
   "metadata": {},
   "source": [
    "**1. What is a Gated Recurrent Unit (GRU), and how does it differ from LSTMs?**\n",
    "\n",
    "\n",
    "### ğŸ§  **GRU (Gated Recurrent Unit)**\n",
    "\n",
    "It's a type of RNN that helps remember info from past steps, like LSTM, but **simpler** and **faster** âš¡\n",
    "\n",
    "### ğŸ” **GRU vs LSTM**\n",
    "\n",
    "| Feature     | GRU ğŸ§                  | LSTM ğŸ§                       |\n",
    "| ----------- | ---------------------- | ---------------------------- |\n",
    "| Gates       | 2ï¸âƒ£ (Update & Reset)   | 3ï¸âƒ£ (Input, Forget, Output)  |\n",
    "| Memory Cell | âŒ No separate cell     | âœ… Has memory cell            |\n",
    "| Speed       | âš¡ Faster               | ğŸ¢ Slower                    |\n",
    "| Simplicity  | âœ… Simple               | âŒ Complex                    |\n",
    "| Performance | ğŸ‘ Good for short data | ğŸ’ª Better for long sequences |\n",
    "\n",
    "\n",
    "**GRU is best** when you want quick results\n",
    "\n",
    "**LSTM is better** when you need to remember long info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ac3ce",
   "metadata": {},
   "source": [
    "**2. What is the difference between a fully connected layer and a convolutional layer?**\n",
    "\n",
    "\n",
    "##### ğŸ§  **Fully Connected Layer (Dense Layer)**\n",
    "\n",
    "* Every neuron is **connected to all** neurons in the next layer ğŸ”—\n",
    "* Used at the **end** of CNNs to make final decisions\n",
    "* Needs **more memory & time** ğŸ’¾âŒ›\n",
    "\n",
    "##### ğŸ§  **Convolutional Layer**\n",
    "\n",
    "* Uses **filters** to scan small parts of the image ğŸ–¼ï¸ğŸ”\n",
    "* Captures **patterns like edges, shapes, textures**\n",
    "* Needs **less memory**, more efficient ğŸš€\n",
    "\n",
    "##### ğŸ” **Key Differences:**\n",
    "\n",
    "| Feature     | Convolutional Layer ğŸ§© | Fully Connected Layer ğŸ”—     |\n",
    "| ----------- | ---------------------- | ---------------------------- |\n",
    "| Connections | Local (small regions)  | Global (all nodes connected) |\n",
    "| Parameters  | Fewer ğŸ’¡               | More ğŸ”¢                      |\n",
    "| Usage       | Feature extraction ğŸ–¼ï¸ | Final prediction ğŸ¯          |\n",
    "| Input Type  | 2D (image)             | 1D (flattened vector)        |\n",
    "\n",
    "- CNN layer = Smart pattern finder\n",
    "- FC layer = Final decision maker âœ…\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56663c68",
   "metadata": {},
   "source": [
    "**3. What is a pooling layer in a CNN, and what purpose does it serve?**\n",
    "\n",
    "### ğŸ§  **Pooling Layer in CNN**\n",
    "\n",
    "It reduces the size of the image (feature map) while keeping the **important info** âœ…\n",
    "\n",
    "### ğŸ”§ **Why use pooling?**\n",
    "\n",
    "* ğŸ§¹ Removes noise\n",
    "* ğŸ’¾ Reduces computation\n",
    "* ğŸ§  Focuses on **important features**\n",
    "\n",
    "### ğŸ” Common Types:\n",
    "\n",
    "| Type         | What it does               |\n",
    "| ------------ | -------------------------- |\n",
    "| **Max Pool** | Keeps the biggest value ğŸ’ª |\n",
    "| **Avg Pool** | Takes average value ğŸ“Š     |\n",
    "\n",
    "### ğŸ” Example:\n",
    "\n",
    "From `2x2 â†’ 1 value` (like keeping the max)\n",
    "This helps model to be faster + stronger ğŸ’¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ab9ec",
   "metadata": {},
   "source": [
    "**4. What is the role of a softmax function in deep learning models?**\n",
    "\n",
    "### ğŸ§  **Softmax Function**\n",
    "\n",
    "It converts raw scores (logits) into **probabilities** ğŸ“Š\n",
    "\n",
    "Used in the **last layer** for **multi-class classification** ğŸ·ï¸\n",
    "\n",
    "### ğŸ” Role:\n",
    "\n",
    "* ğŸ¯ Shows **which class is most likely**\n",
    "\n",
    "* âœ… All outputs add up to 1\n",
    "\n",
    "* ğŸ”¢ Example output: \\[0.1, 0.7, 0.2] â†’ Class 2 is highest!\n",
    "\n",
    "**Use softmax** when you have **more than 2 classes** in output ğŸ”¥\n",
    "\n",
    "It's like the model saying: â€œI'm 70% sure it's class 2!â€ ğŸ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40697be2",
   "metadata": {},
   "source": [
    "**5. Can you explain the concept of autoencoders and their applications?** \n",
    "\n",
    "\n",
    "### ğŸ§  **Autoencoder = Encoder + Decoder**\n",
    "\n",
    "It learns to **compress** the data (like zip) and then **rebuild** it back ğŸ’¾ğŸ”\n",
    "No need for labels = **unsupervised learning** ğŸ˜‡\n",
    "\n",
    "### ğŸ§© **Parts:**\n",
    "\n",
    "* **Encoder** ğŸ§ : Turns input into small code (compressed)\n",
    "* **Decoder** ğŸ› ï¸: Rebuilds original from the code\n",
    "\n",
    "### ğŸ¯ **Applications:**\n",
    "\n",
    "* ğŸ§¹ Noise removal from images\n",
    "* ğŸ”’ Anomaly detection\n",
    "* ğŸ§¬ Dimensionality reduction\n",
    "* ğŸ–¼ï¸ Image generation (like faces, digits)\n",
    "\n",
    "Simple idea: **Learn to copy input smartly** ğŸ’¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5de3d0",
   "metadata": {},
   "source": [
    "**6. What types of documents can be processed using OCR?**\n",
    "\n",
    "### ğŸ“š **OCR can process these types of documents:**\n",
    "\n",
    "* ğŸ“„ **Printed documents** (Books, Newspapers)\n",
    "* ğŸ§¾ **Invoices & Bills**\n",
    "* ğŸ†” **ID cards & Passports**\n",
    "* ğŸ“¦ **Shipping labels**\n",
    "* ğŸ“ƒ **Forms & Surveys**\n",
    "* ğŸ“ **Handwritten notes** (with deep learning OCR)\n",
    "\n",
    "ğŸ’¡ OCR is super useful in offices, banks, hospitals, and more! ğŸ¢ğŸ¥ğŸ“¦\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa24c41",
   "metadata": {},
   "source": [
    "**7. What is the difference between OCR, ICR, and OMR?**\n",
    "\n",
    "\n",
    "| ğŸ§  Tech | ğŸ’¬ Full Form                      | ğŸ“Œ Purpose                                          |\n",
    "| ------- | --------------------------------- | --------------------------------------------------- |\n",
    "| **OCR** | Optical Character Recognition     | Reads **printed or handwritten text** ğŸ“            |\n",
    "| **ICR** | Intelligent Character Recognition | Reads **handwritten** text more smartly using AI ğŸ§  |\n",
    "| **OMR** | Optical Mark Recognition          | Detects **marks/checks** like in exams âœ…âŒ           |\n",
    "\n",
    "\n",
    "ğŸ” OCR = text\n",
    "ğŸ§  ICR = smart handwriting\n",
    "âœ… OMR = mark detection (like MCQs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29578337",
   "metadata": {},
   "source": [
    "**8. What is the accuracy rate of OCR technology?** \n",
    "\n",
    "### ğŸ“Š **OCR Accuracy Rate:**\n",
    "\n",
    "* ğŸ–¨ï¸ **Printed text** â†’ **95% to 99%** âœ…\n",
    "* âœï¸ **Handwritten text** â†’ **60% to 90%** âœï¸ (depends on clarity)\n",
    "\n",
    "\n",
    "ğŸ” Accuracy depends on:\n",
    "\n",
    "* Text quality ğŸ“„\n",
    "* Image clarity ğŸ–¼ï¸\n",
    "* Font type ğŸ”¤\n",
    "* OCR model used ğŸ¤–\n",
    "\n",
    "ğŸ’¡ Deep learning-based OCR gives higher accuracy! ğŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ecc674",
   "metadata": {},
   "source": [
    "**9. How can OCR accuracy be improved?**\n",
    "\n",
    "### ğŸ” **Tips to Improve OCR Accuracy:**\n",
    "\n",
    "1. ğŸ§¼ **Clean image** â€“ No noise, blur, or shadows\n",
    "2. ğŸ–¼ï¸ **High resolution** â€“ Use clear images (300 DPI is great)\n",
    "3. ğŸ“ **Proper alignment** â€“ Make text straight (no tilt)\n",
    "4. ğŸ”¤ **Standard fonts** â€“ Use easy-to-read fonts (like Arial)\n",
    "5. ğŸŒˆ **Good contrast** â€“ Dark text on light background (or vice versa)\n",
    "6. ğŸ¤– **Use deep learning OCR** â€“ like Tesseract + LSTM or CRNN\n",
    "7. âœ‚ï¸ **Preprocessing** â€“ Resize, binarize, and denoise before OCR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d2afec",
   "metadata": {},
   "source": [
    "**10. What are the limitations of OCR?**\n",
    "\n",
    "### âŒ **Limitations of OCR:**\n",
    "\n",
    "1. ğŸ“‰ **Low accuracy** with blurry or noisy images\n",
    "2. âœï¸ **Hard to read handwriting** (ICR needed for that)\n",
    "3. ğŸ”¤ **Stylish or distorted fonts** confuse OCR\n",
    "4. ğŸ“ **Skewed or rotated text** lowers detection\n",
    "5. ğŸŒˆ **Low contrast** between text & background = bad results\n",
    "6. ğŸ“„ **Complex layouts** (tables, columns) can mess up the reading\n",
    "7. ğŸŒ **Multilingual text** needs special models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8575aa2b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
